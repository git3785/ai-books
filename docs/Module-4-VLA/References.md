---
sidebar_position: 20
title: "References"
---

# References: Module 4 - Vision-Language-Action (VLA) Integration

## Authoritative Sources

### Academic Papers
1. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2022). Robust speech recognition via large-scale weak supervision. *arXiv preprint arXiv:2212.04356*.

2. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. *Advances in neural information processing systems*, 33, 1877-1901.

3. Siciliano, B., & Khatib, O. (Eds.). (2016). Springer handbook of robotics. *Springer Publishing*.

4. Kaptein, R., & Kohlsdorf, D. (2021). Whisper: Robust speech recognition via large-scale weak supervision. *OpenAI*, 1-15.

5. Kress-Gazit, H., Fainekos, G. E., & Pappas, G. J. (2009). Temporal-logic-based reactive mission and motion planning. *IEEE Transactions on Robotics*, 25(6), 1370-1381.

### Official Documentation
6. OpenAI. (2023). Whisper API Documentation. https://platform.openai.com/docs/guides/speech-to-text

7. OpenAI. (2023). GPT-4 API Documentation. https://platform.openai.com/docs/guides/chat

8. ROS 2 Documentation. (2023). Action Architecture. https://docs.ros.org/en/humble/Concepts/About-Actions.html

9. NVIDIA Isaac ROS Documentation. (2023). https://nvidia-isaac-ros.github.io/repositories_and_packages/index.html

10. Jetson Orin Nano/NX Documentation. (2023). https://developer.nvidia.com/embedded/jetson-orin-nano-devkit

## Additional Resources

- OpenAI. (2023). Best practices for speech-to-text applications.
- ROS 2. (2023). Integration guide for multimodal systems.
- NVIDIA. (2023). Edge AI deployment guidelines for robotics.